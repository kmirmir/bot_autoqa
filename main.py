import streamlit as st
import json
from bot_validator import (
    analyze_bot_json, validate_bot_json, suggest_fixes,
    export_excel, export_pdf, plot_error_types
)
import os
import pandas as pd
import plotly.express as px
import openai
from dotenv import load_dotenv
from fpdf import FPDF
from collections import defaultdict
import re
from io import BytesIO
import html  # html entity decoding
from openai import OpenAI  # Add for v1 API
from pydantic import BaseModel
import time  # For timing debug
from concurrent.futures import ThreadPoolExecutor, as_completed  # For parallel typo check

# .env íŒŒì¼ì˜ í™˜ê²½ë³€ìˆ˜ ìë™ ë¡œë“œ
load_dotenv()

st.sidebar.title("Auto QA ë´‡ ê²€ìˆ˜")
menu = st.sidebar.radio("ë©”ë‰´", [
    "ëŒ€ì‹œë³´ë“œ",
    "JSON êµ¬ì¡° íŒŒì•…",
    "Response Text ê²€ì¶œ",
    "QA ê²€ìˆ˜ ê²°ê³¼"
])

st.markdown("""
    <style>
    .css-18e3th9 {padding-top: 0rem;}
    .css-1d391kg {padding-top: 0rem;}
    </style>
""", unsafe_allow_html=True)

# ì—…ë¡œë“œ íŒŒì¼ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ì—¬ ëª¨ë“  ë©”ë‰´ì—ì„œ ê³µìœ 
if 'shared_json_data' not in st.session_state:
    st.session_state['shared_json_data'] = None

uploaded_file = st.file_uploader("JSON íŒŒì¼ ì—…ë¡œë“œ", type=["json"], key="main_json")
if uploaded_file is not None:
    try:
        st.session_state['shared_json_data'] = json.load(uploaded_file)
    except Exception as e:
        st.error(f"JSON íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

data = st.session_state['shared_json_data']

# ë©”ë‰´ë³„ Title ë™ì  ë³€ê²½
if menu == "ëŒ€ì‹œë³´ë“œ":
    st.title("ğŸ¤– ë´‡ ì‹œë‚˜ë¦¬ì˜¤ ìë™ ê²€ìˆ˜ ëŒ€ì‹œë³´ë“œ")
elif menu == "QA ê²€ìˆ˜ ê²°ê³¼":
    st.title("ğŸ¤– ì˜¤ë¥˜ ìƒì„¸ ë° ìˆ˜ì • ì œì•ˆ")
elif menu == "JSON êµ¬ì¡° íŒŒì•…":
    st.title("ğŸ¤– ë´‡ ë¹Œë” JSON êµ¬ì¡° íŒŒì•…í•˜ê¸°")
elif menu == "Response Text ê²€ì¶œ":
    st.title("ğŸ¤– Text ì˜¤íƒ€ ê²€ì¶œ ë° êµì • ì œì•ˆ")

def check_openai_key():
    try:
        openai.api_key = os.getenv("OPENAI_API_KEY")
        if not openai.api_key:
            return False, "í™˜ê²½ë³€ìˆ˜ì— OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤."
        # ìµœì‹  openai íŒ¨í‚¤ì§€(1.x) ë°©ì‹
        openai.models.list()
        return True, "OpenAI API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤."
    except Exception as e:
        return False, f"OpenAI API í‚¤ ì˜¤ë¥˜: {e}"

if st.button("OpenAI API í‚¤ ì •ìƒë™ì‘ ì²´í¬"):
    ok, msg = check_openai_key()
    if ok:
        st.success(msg)
    else:
        st.error(msg)

# Flowë³„ ì„œë¹„ìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ ìš”ì•½ (Pageê°„ ì´ë™ ê³ ë ¤, ìì—°ì–´)
def summarize_flow_service_natural(data):
    flows = data['context']['flows']
    summaries = []
    for flow in flows:
        flow_name = flow['name']
        pages = flow['pages']
        page_names = [page['name'] for page in pages]
        # pageê°„ ì´ë™ í•´ì„
        page_links = {}
        for page in pages:
            for handler in page.get('handlers', []):
                target = handler.get('transitionTarget', {})
                if target.get('type') == 'CUSTOM' and target.get('page'):
                    page_links.setdefault(page['name'], set()).add(target['page'])
        # ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤ íë¦„ ì¶”ì¶œ (DFS)
        def dfs(path, visited):
            cur = path[-1]
            if cur not in page_links or not page_links[cur]:
                return [path]
            flows = []
            for nxt in page_links[cur]:
                if nxt in visited:
                    continue
                flows.extend(dfs(path + [nxt], visited | {nxt}))
            return flows
        scenario_paths = []
        if pages:
            scenario_paths = dfs([pages[0]['name']], {pages[0]['name']})
        # ìì—°ì–´ ì‹œë‚˜ë¦¬ì˜¤ ìš”ì•½
        scenario_desc = ""
        if scenario_paths:
            # ê°€ì¥ ê¸´ ê²½ë¡œë¥¼ ëŒ€í‘œ ì‹œë‚˜ë¦¬ì˜¤ë¡œ
            main_path = max(scenario_paths, key=len)
            scenario_desc = f"ì´ FlowëŠ” '{main_path[0]}'ì—ì„œ ì‹œì‘í•˜ì—¬ "
            if len(main_path) > 2:
                scenario_desc += ", ".join(main_path[1:-1]) + f"ë¥¼ ê±°ì³ '{main_path[-1]}'ë¡œ ì´ë™í•˜ëŠ” ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í¬í•¨í•©ë‹ˆë‹¤."
            elif len(main_path) == 2:
                scenario_desc += f"'{main_path[1]}'ë¡œ ì´ë™í•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í¬í•¨í•©ë‹ˆë‹¤."
            else:
                scenario_desc += "ë‹¨ì¼ í˜ì´ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        else:
            scenario_desc = "ì‹œë‚˜ë¦¬ì˜¤ íë¦„ì„ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        # ì•ˆë‚´ë¬¸ ì¶”ì¶œ (ì²« Pageì˜ record.text ë˜ëŠ” action.responsesì˜ record.text)
        first_page = pages[0] if pages else None
        guide_text = None
        if first_page:
            if 'record' in first_page and first_page['record'] and 'text' in first_page['record']:
                guide_text = first_page['record']['text']
            elif 'action' in first_page and 'responses' in first_page['action']:
                for resp in first_page['action']['responses']:
                    if 'record' in resp and resp['record'] and 'text' in resp['record']:
                        guide_text = resp['record']['text']
                        break
        # ìš”ì•½ë¬¸ ìƒì„±
        summary = f"**Flow: {flow_name}**\n"
        if guide_text:
            summary += f"- ì£¼ìš” ì•ˆë‚´: {guide_text}\n"
        summary += f"- ì£¼ìš” í˜ì´ì§€: {', '.join(page_names[:3])}\n"
        summary += f"- {scenario_desc}"
        summaries.append(summary)
    return summaries

# í•¸ë“¤ëŸ¬/ë³€ìˆ˜ ìƒì„¸ ìš”ì•½ í…Œì´ë¸” ìƒì„± (ë³€ìˆ˜ ìƒì„¸ ì„¤ëª… í¬í•¨)
def get_handler_variable_details(data):
    flows = data['context']['flows']
    handler_rows = []
    variable_rows = []
    variable_usage = {}  # ë³€ìˆ˜ëª…: [dict(Flow, Page, Handler Type, Condition, Value, Where)]
    for flow in flows:
        flow_name = flow['name']
        for page in flow['pages']:
            page_name = page['name']
            for handler in page.get('handlers', []):
                handler_type = handler.get('type')
                cond = handler.get('conditionStatement', None)
                handler_rows.append({
                    'Flow': flow_name,
                    'Page': page_name,
                    'Handler Type': handler_type,
                    'Condition': cond if cond else ''
                })
                # ë³€ìˆ˜
                for preset in handler.get('action', {}).get('parameterPresets', []):
                    row = {
                        'Flow': flow_name,
                        'Page': page_name,
                        'Handler Type': handler_type,
                        'Condition': cond if cond else '',
                        'Variable': preset['name'],
                        'Value': preset.get('value', ''),
                        'Where': 'action.parameterPresets'
                    }
                    variable_rows.append(row)
                    variable_usage.setdefault(preset['name'], []).append(row)
                for preset in handler.get('parameterPresets', []):
                    row = {
                        'Flow': flow_name,
                        'Page': page_name,
                        'Handler Type': handler_type,
                        'Condition': cond if cond else '',
                        'Variable': preset['name'],
                        'Value': preset.get('value', ''),
                        'Where': 'parameterPresets'
                    }
                    variable_rows.append(row)
                    variable_usage.setdefault(preset['name'], []).append(row)
    handler_df = pd.DataFrame(handler_rows)
    variable_df = pd.DataFrame(variable_rows)
    return handler_df, variable_df, variable_usage

# Intent/Entity ìš”ì•½ ë° ì˜¤ë¥˜ ê²€ìˆ˜ í•¨ìˆ˜
def get_intent_entity_summary(data):
    # Intents
    intents = []
    intent_names = set()
    for intent in data['context'].get('openIntents', []) + data['context'].get('userIntents', []):
        name = intent.get('name')
        intent_names.add(name)
        example = ", ".join(intent.get('sentences', [])[:3])
        intents.append({
            'Intentëª…': name,
            'ì˜ˆì‹œ ë¬¸ì¥': example
        })
    # Entities
    entities = []
    entity_names = set()
    for entity in data['context'].get('customEntities', []):
        name = entity.get('name')
        entity_names.add(name)
        for v in entity.get('entityValues', []):
            rep = v.get('representative')
            synonyms = ", ".join(v.get('synonyms', []))
            entities.append({
                'Entityëª…': name,
                'ëŒ€í‘œê°’': rep,
                'ë™ì˜ì–´': synonyms
            })
    # Intent ì˜¤ë¥˜ ê²€ìˆ˜(ì¤‘ë³µ, ë¯¸ì‚¬ìš© ë“±)
    intent_errors = []
    if len(intent_names) != len(intents):
        intent_errors.append({'ì˜¤ë¥˜': 'ì¤‘ë³µ Intentëª… ì¡´ì¬'})
    # Entity ì˜¤ë¥˜ ê²€ìˆ˜(ì¤‘ë³µ, ë¯¸ì‚¬ìš© ë“±)
    entity_errors = []
    if len(entity_names) != len(data['context'].get('customEntities', [])):
        entity_errors.append({'ì˜¤ë¥˜': 'ì¤‘ë³µ Entityëª… ì¡´ì¬'})
    # ë¯¸ì‚¬ìš© Intent/Entity(í”Œë¡œìš°/í•¸ë“¤ëŸ¬ì—ì„œ ì°¸ì¡°ë˜ì§€ ì•ŠëŠ” ê²½ìš°)
    # (ê°„ë‹¨íˆ í”Œë¡œìš° ë‚´ intentTrigger, conditionStatement ë“±ì—ì„œ ì°¸ì¡°ë˜ëŠ”ì§€ í™•ì¸)
    used_intents = set()
    used_entities = set()
    for flow in data['context'].get('flows', []):
        for page in flow.get('pages', []):
            for handler in page.get('handlers', []):
                # intentTrigger
                if 'intentTrigger' in handler:
                    used_intents.add(handler['intentTrigger'].get('name'))
                # conditionStatement ë‚´ intentëª…/ì—”í‹°í‹°ëª…
                cond = handler.get('conditionStatement', '')
                for iname in intent_names:
                    if iname and iname in str(cond):
                        used_intents.add(iname)
                for ename in entity_names:
                    if ename and ename in str(cond):
                        used_entities.add(ename)
    unused_intents = intent_names - used_intents
    unused_entities = entity_names - used_entities
    if unused_intents:
        intent_errors.append({'ì˜¤ë¥˜': f'ë¯¸ì‚¬ìš© Intent: {", ".join(unused_intents)}'})
    if unused_entities:
        entity_errors.append({'ì˜¤ë¥˜': f'ë¯¸ì‚¬ìš© Entity: {", ".join(unused_entities)}'})
    return pd.DataFrame(intents), pd.DataFrame(entities), pd.DataFrame(intent_errors), pd.DataFrame(entity_errors)

# íƒ­ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ CSS ì¶”ê°€
st.markdown('''
    <style>
    /* íƒ­ ë°” ì „ì²´ ë°°ê²½ ë° êµ¬ë¶„ì„  */
    .stTabs [data-baseweb="tab-list"] {
        background: #fafaff;
        border-bottom: 2px solid #e0e0e0;
        padding: 1.2rem 2rem 0 2rem;
        border-radius: 2rem 2rem 0 0;
        box-shadow: 0 4px 16px rgba(108,71,255,0.06);
        margin-bottom: 0.5rem;
    }
    /* íƒ­ ë²„íŠ¼ */
    .stTabs [data-baseweb="tab"] {
        font-size: 1.15rem;
        font-weight: 700;
        color: #888;
        padding: 0.7rem 2.2rem 0.7rem 2.2rem;
        margin-right: 1.2rem;
        border-radius: 1.5rem 1.5rem 0 0;
        background: #f5f6fa;
        transition: background 0.2s, color 0.2s;
        border: none;
        outline: none;
    }
    /* í™œì„± íƒ­ */
    .stTabs [aria-selected="true"] {
        background: #fff;
        color: #2d2d3a;
        border-bottom: 3px solid #6c47ff;
        box-shadow: 0 2px 8px rgba(108,71,255,0.07);
        z-index: 2;
    }
    /* ë¹„í™œì„± íƒ­ hover íš¨ê³¼ */
    .stTabs [data-baseweb="tab"]:hover {
        background: #ececff;
        color: #6c47ff;
    }
    /* íƒ­ ë‚´ ì œëª© ê°•ì¡° */
    .tab-section-title {
        font-size: 2.1rem;
        font-weight: 900;
        color: #2d2d3a;
        margin-top: 1.2rem;
        margin-bottom: 1.2rem;
        letter-spacing: -1px;
        display: flex;
        align-items: center;
        gap: 0.7rem;
    }
    .tab-section-title .icon {
        font-size: 2.2rem;
        color: #6c47ff;
        vertical-align: middle;
    }
    </style>
''', unsafe_allow_html=True)

# --- JSON êµ¬ì¡° íŒŒì•… ê¸°ëŠ¥ ì™„ì „ ë‚´ì¥ (structure.py ë¶ˆí•„ìš”) ---
def summarize_action(action):
    """í•µì‹¬ keyë§Œ ìš”ì•½ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not isinstance(action, dict) or not action:
        return ""
    keys = [k for k in action.keys() if action[k]]
    summary = []
    for k in keys:
        v = action[k]
        if isinstance(v, list):
            summary.append(f"{k}: {len(v)}ê°œ")
        elif isinstance(v, dict):
            summary.append(f"{k}: dict")
        else:
            summary.append(f"{k}: {str(v)[:20]}")
    return ", ".join(summary) if summary else "-"

def summarize_list(val):
    if isinstance(val, list):
        if not val:
            return "-"
        # ë¦¬ìŠ¤íŠ¸ê°€ dictë©´ ì£¼ìš” keyë§Œ ìš”ì•½
        if all(isinstance(x, dict) for x in val):
            return "; ".join(
                [", ".join(f"{k}:{str(v)[:10]}" for k, v in x.items()) for x in val]
            )
        return ", ".join(str(x) for x in val)
    elif val is None or val == "":
        return "-"
    else:
        return str(val)

def parse_bot_structure_from_data(data):
    flows = data["context"].get("flows", [])
    intents = data["context"].get("openIntents", []) + data["context"].get("userIntents", [])
    entities = data["context"].get("customEntities", [])

    flow_rows = []
    for flow in flows:
        flow_name = flow.get("name")
        for page in flow.get("pages", []):
            page_name = page.get("name")
            action = page.get("action", {})
            parameters = page.get("parameters", [])
            for handler in page.get("handlers", []):
                handler_type = handler.get("type")
                handler_id = handler.get("id", "")
                handler_action = handler.get("action", {})
                handler_param_presets = handler_action.get("parameterPresets", [])
                condition = handler.get("conditionStatement", "")
                event_trigger = handler.get("eventTrigger", {})
                intent_trigger = handler.get("intentTrigger", {})
                transition_target = handler.get("transitionTarget", {})
                flow_rows.append({
                    "Flow": flow_name,
                    "Page": page_name,
                    "Page_Action": summarize_action(action),
                    "Page_Parameters": summarize_list(parameters),
                    "Handler_ID": handler_id,
                    "Handler_Type": handler_type,
                    "Handler_Condition": condition,
                    "Handler_Action": summarize_action(handler_action),
                    "Handler_ParameterPresets": summarize_list(handler_param_presets),
                    "Handler_EventTrigger": str(event_trigger) if event_trigger else "",
                    "Handler_IntentTrigger": str(intent_trigger) if intent_trigger else "",
                    "Handler_TransitionTarget": str(transition_target) if transition_target else "",
                })
            if not page.get("handlers"):
                flow_rows.append({
                    "Flow": flow_name,
                    "Page": page_name,
                    "Page_Action": summarize_action(action),
                    "Page_Parameters": summarize_list(parameters),
                    "Handler_ID": "",
                    "Handler_Type": "",
                    "Handler_Condition": "",
                    "Handler_Action": "",
                    "Handler_ParameterPresets": "",
                    "Handler_EventTrigger": "",
                    "Handler_IntentTrigger": "",
                    "Handler_TransitionTarget": "",
                })
    flow_df = pd.DataFrame(flow_rows)

    intent_rows = []
    for intent in intents:
        intent_rows.append({
            "Intent_Name": intent.get("name"),
            "Sentences": ", ".join(intent.get("sentences", [])),
            "RepresentativeSentences": ", ".join(intent.get("representativeSentences", [])),
        })
    intent_df = pd.DataFrame(intent_rows)

    entity_rows = []
    for entity in entities:
        entity_name = entity.get("name")
        for value in entity.get("entityValues", []):
            entity_rows.append({
                "Entity_Name": entity_name,
                "Representative": value.get("representative"),
                "Synonyms": ", ".join(value.get("synonyms", [])),
            })
    entity_df = pd.DataFrame(entity_rows)

    return flow_df, intent_df, entity_df

def extract_responses(data):
    """
    ê° Flow/Pageë³„ë¡œ Response í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    [{Flow, Page, Response Text, ...}]
    """
    rows = []
    for flow in data['context'].get('flows', []):
        flow_name = flow.get('name')
        for page in flow.get('pages', []):
            page_name = page.get('name')
            # Page-level action.responses
            responses = []
            if 'action' in page and 'responses' in page['action']:
                responses.extend(page['action']['responses'])
            # Handler-level action.responses
            for handler in page.get('handlers', []):
                if 'action' in handler and 'responses' in handler['action']:
                    responses.extend(handler['action']['responses'])
            for resp in responses:
                # responseëŠ” dict, textëŠ” resp['record']['text'] ë˜ëŠ” resp['text']
                text = None
                if 'record' in resp and resp['record'] and 'text' in resp['record']:
                    text = resp['record']['text']
                elif 'text' in resp:
                    text = resp['text']
                if text:
                    rows.append({
                        'Flow': flow_name,
                        'Page': page_name,
                        'Response Text': text
                    })
    return rows

# ì˜¤íƒ€ ê²€ì¶œ(OpenAI)
def check_typo_openai(text):
    """
    OpenAIë¥¼ ì´ìš©í•´ í…ìŠ¤íŠ¸ì— ì˜¤íƒ€ê°€ ìˆëŠ”ì§€ ê²€ì‚¬ (ê°„ë‹¨ í”„ë¡¬í”„íŠ¸)
    ì˜¤íƒ€ê°€ ìˆìœ¼ë©´ True, ì—†ìœ¼ë©´ False ë°˜í™˜
    """
    try:
        openai.api_key = os.getenv("OPENAI_API_KEY")
        prompt = f"ë‹¤ìŒ ë¬¸ì¥ì— ë§ì¶¤ë²•ì´ë‚˜ ì˜¤íƒ€ê°€ ìˆìœ¼ë©´ 'ì˜¤íƒ€ ìˆìŒ', ì—†ìœ¼ë©´ 'ì˜¤íƒ€ ì—†ìŒ'ë§Œ ë‹µí•´ì¤˜.\në¬¸ì¥: {text}"
        client = openai.OpenAI(api_key=openai.api_key)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ì–´ ë§ì¶¤ë²• ê²€ì‚¬ê¸°ì•¼."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=10
        )
        result = response.choices[0].message.content.strip()
        return result
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}"

def extract_response_texts_by_flow(data):
    """
    ê° Flow/Pageë³„ë¡œ action.responsesì˜ <p>...</p> í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
    [{Flow, Page, ìœ„ì¹˜, Handler Type, Condition, Response Type, TemplateId, Response Text}]
    """
    rows = []
    for flow in data['context'].get('flows', []):
        flow_name = flow.get('name')
        for page in flow.get('pages', []):
            page_name = page.get('name')
            # Page-level action.responses
            if 'action' in page and 'responses' in page['action']:
                for resp in page['action']['responses']:
                    text_candidates = []
                    # 1. record.text
                    if 'record' in resp and resp['record'] and 'text' in resp['record']:
                        text_candidates.append(resp['record']['text'])
                    # 2. text
                    if 'text' in resp:
                        text_candidates.append(resp['text'])
                    # 3. MESSAGE íƒ€ì…ì˜ customPayload.content.item ë‚´ë¶€ section/item/text.text
                    template_id = None
                    if resp.get('type') == 'MESSAGE':
                        custom_payload = resp.get('customPayload', {})
                        content = custom_payload.get('content', {})
                        template_id = content.get('templateId') or custom_payload.get('templateId')
                        items = content.get('item', [])
                        for section in items:
                            if isinstance(section, dict) and 'section' in section:
                                section_obj = section['section']
                                section_items = section_obj.get('item', [])
                                for section_item in section_items:
                                    if 'text' in section_item and isinstance(section_item['text'], dict):
                                        t = section_item['text'].get('text')
                                        if t:
                                            text_candidates.append(t)
                    for text in text_candidates:
                        if not text:
                            continue
                        p_texts = re.findall(r'<p>(.*?)</p>', text, re.DOTALL)
                        for p in p_texts:
                            clean_p = p.strip()
                            # <br> ë° <br/> íƒœê·¸ ì œê±°
                            clean_p = re.sub(r'<br\s*/?>', '', clean_p, flags=re.IGNORECASE)
                            if clean_p:  # null/ë¹ˆê°’ ì œì™¸
                                clean_p = html.unescape(clean_p)  # HTML entity decode
                                rows.append({
                                    'Flow': flow_name,
                                    'Page': page_name,
                                    'ìœ„ì¹˜': 'Page',
                                    'Handler Type': '',
                                    'Condition': '',
                                    'Response Type': resp.get('type', ''),
                                    'TemplateId': template_id,
                                    'Response Text': clean_p
                                })
            # Handler-level action.responses
            for handler in page.get('handlers', []):
                handler_type = handler.get('type', '')
                cond = handler.get('conditionStatement', '')
                if 'action' in handler and 'responses' in handler['action']:
                    for resp in handler['action']['responses']:
                        text_candidates = []
                        # 1. record.text
                        if 'record' in resp and resp['record'] and 'text' in resp['record']:
                            text_candidates.append(resp['record']['text'])
                        # 2. text
                        if 'text' in resp:
                            text_candidates.append(resp['text'])
                        # 3. MESSAGE íƒ€ì…ì˜ customPayload.content.item ë‚´ë¶€ section/item/text.text
                        template_id = None
                        if resp.get('type') == 'MESSAGE':
                            custom_payload = resp.get('customPayload', {})
                            content = custom_payload.get('content', {})
                            template_id = content.get('templateId') or custom_payload.get('templateId')
                            items = content.get('item', [])
                            for section in items:
                                if isinstance(section, dict) and 'section' in section:
                                    section_obj = section['section']
                                    section_items = section_obj.get('item', [])
                                    for section_item in section_items:
                                        if 'text' in section_item and isinstance(section_item['text'], dict):
                                            t = section_item['text'].get('text')
                                            if t:
                                                text_candidates.append(t)
                        for text in text_candidates:
                            if not text:
                                continue
                            p_texts = re.findall(r'<p>(.*?)</p>', text, re.DOTALL)
                            for p in p_texts:
                                clean_p = p.strip()
                                # <br> ë° <br/> íƒœê·¸ ì œê±°
                                clean_p = re.sub(r'<br\s*/?>', '', clean_p, flags=re.IGNORECASE)
                                if clean_p:  # null/ë¹ˆê°’ ì œì™¸
                                    clean_p = html.unescape(clean_p)  # HTML entity decode
                                    rows.append({
                                        'Flow': flow_name,
                                        'Page': page_name,
                                        'ìœ„ì¹˜': 'Handler',
                                        'Handler Type': handler_type,
                                        'Condition': cond,
                                        'Response Type': resp.get('type', ''),
                                        'TemplateId': template_id,
                                        'Response Text': clean_p
                                    })
    # null/ë¹ˆê°’ row ì „ì²´ ì œì™¸ (í˜¹ì‹œë¼ë„ ë‚¨ì•„ìˆì„ ê²½ìš°)
    rows = [row for row in rows if row.get('Response Text') not in [None, '', 'null']]
    return rows

# ì˜¤íƒ€ ê²€ì¶œ(OpenAI) - Flow ë‹¨ìœ„

def check_typo_openai_flow(flow_texts):
    """
    í•œ Flowì˜ ëª¨ë“  Response Textë¥¼ í•©ì³ì„œ ì˜¤íƒ€ ê²€ì¶œ(OpenAI) ìš”ì²­
    ì˜¤íƒ€ê°€ ìˆìœ¼ë©´ 'ì˜¤íƒ€ ìˆìŒ', ì—†ìœ¼ë©´ 'ì˜¤íƒ€ ì—†ìŒ' ë°˜í™˜
    """
    try:
        openai.api_key = os.getenv("OPENAI_API_KEY")
        joined = '\n'.join(flow_texts)
        prompt = f"ë‹¤ìŒ ì—¬ëŸ¬ ë¬¸ì¥ì— ë§ì¶¤ë²•ì´ë‚˜ ì˜¤íƒ€ê°€ ìˆìœ¼ë©´ 'ì˜¤íƒ€ ìˆìŒ', ì—†ìœ¼ë©´ 'ì˜¤íƒ€ ì—†ìŒ'ë§Œ ë‹µí•´ì¤˜.\në¬¸ì¥ë“¤:\n{joined}"
        client = openai.OpenAI(api_key=openai.api_key)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ì–´ ë§ì¶¤ë²• ê²€ì‚¬ê¸°ì•¼."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=10
        )
        result = response.choices[0].message.content.strip()
        return result
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}"

class TypoCheckResult(BaseModel):
    text: str
    typo: bool
    reason: str = ""

# ì˜¤íƒ€ ê²€ì¶œ(OpenAI) - Responseë³„ JSON ê²°ê³¼ ë°˜í™˜

def check_typo_openai_responses_json(response_texts):
    """
    ì—¬ëŸ¬ Response Textë¥¼ ë°›ì•„ ê°ê°ì— ëŒ€í•´ ì˜¤íƒ€ ì—¬ë¶€ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜ (OpenAI + Pydantic)
    [{text, typo, reason} ...]
    ë¬´ì˜ë¯¸í•œ ë¬¸ìì—´(ê³µë°±, íŠ¹ìˆ˜ë¬¸ìë§Œ, ë§¤ìš° ì§§ì€ ê²½ìš° ë“±)ì€ OpenAIì— ë³´ë‚´ì§€ ì•Šê³  ë°”ë¡œ typo=True ì²˜ë¦¬
    """
    import re
    api_key = os.getenv("OPENAI_API_KEY")
    client = OpenAI(api_key=api_key)
    class TypoCheckList(BaseModel):
        results: list[TypoCheckResult]
    prompt = (
        "ì•„ë˜ ì—¬ëŸ¬ ë¬¸ì¥ ê°ê°ì— ëŒ€í•´ ë§ì¶¤ë²•/ì˜¤íƒ€ê°€ ìˆìœ¼ë©´ typo=true, ì—†ìœ¼ë©´ typo=falseë¡œ, ì´ìœ (reason)ì™€ í•¨ê»˜ JSON ë°°ì—´ë¡œ ë‹µí•´ì¤˜. "
        "í˜•ì‹: {\"results\":[{\"text\":..., \"typo\":true/false, \"reason\":...}, ...]}\n"
    )
    # ë¬´ì˜ë¯¸í•œ ë¬¸ìì—´ íŒë³„ í•¨ìˆ˜
    def is_meaningless(text):
        if not text or not str(text).strip():
            return True
        # í•œê¸€ ììŒ/ëª¨ìŒë§Œ ë°˜ë³µ (ì˜ˆ: ã…‡ã…ã…‡ã…‡ã…‡...)
        if re.fullmatch(r'[ã„±-ã…ã…-ã…£]+', text.strip()):
            return True
        # íŠ¹ìˆ˜ë¬¸ì/ê³µë°±ë§Œ (í•œê¸€,ì˜ë¬¸,ìˆ«ì, ì™„ì„±í˜• í•œê¸€ ì—†ìœ¼ë©´)
        if not re.search(r"[A-Za-z0-9ê°€-í£]", text):
            return True
        # ë„ˆë¬´ ì§§ì€ ê²½ìš° (ì˜ˆ: 2ê¸€ì ì´í•˜)
        if len(text.strip()) <= 2:
            return True
        return False
    # ë¶„ë¦¬: ë¬´ì˜ë¯¸/ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸
    meaningless = [t for t in response_texts if is_meaningless(t)]
    meaningful = [t for t in response_texts if not is_meaningless(t)]
    results = []
    # ë¬´ì˜ë¯¸í•œ í…ìŠ¤íŠ¸ëŠ” ë°”ë¡œ typo=True ì²˜ë¦¬
    for t in meaningless:
        results.append(TypoCheckResult(text=t, typo=True, reason="ë¬´ì˜ë¯¸í•œ ë¬¸ìì—´(ê³µë°±/íŠ¹ìˆ˜ë¬¸ì/ë„ˆë¬´ ì§§ìŒ)"))
    if meaningful:
        joined = "\n".join(f"- {t}" for t in meaningful)
        user_content = f"ë¬¸ì¥ ëª©ë¡:\n{joined}"
        response = client.responses.parse(
            model="gpt-4o-2024-08-06",
            input=[
                {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ì–´ ë§ì¶¤ë²• ê²€ì‚¬ê¸°ì•¼."},
                {"role": "user", "content": prompt + user_content},
            ],
            text_format=TypoCheckList,
        )
        results.extend(response.output_parsed.results)
    return results

if menu == "ëŒ€ì‹œë³´ë“œ" and data is not None:
    flows, pages, handlers, variables = analyze_bot_json(data)
    errors = validate_bot_json(data)
    suggestions = suggest_fixes(errors, data)

    tab1, tab2, tab3 = st.tabs([
        "ğŸ“„ ì„œë¹„ìŠ¤ ìš”ì•½",
        "ğŸ› ï¸ í•¸ë“¤ëŸ¬/ë³€ìˆ˜ ìƒì„¸",
        "ğŸ” ì¸í…íŠ¸/ì—”í‹°í‹° ìš”ì•½"
    ])

    # ì •í™•í•œ Page ìˆ˜ ì§‘ê³„ (ëª¨ë“  Flowì˜ Page ì¡°í•©)
    def page_key(page_tuple):
        if isinstance(page_tuple, tuple) and len(page_tuple) == 2:
            flow, page = page_tuple
            if isinstance(page, dict):
                return (flow, page.get('name', str(page)))
            return (flow, str(page))
        return (None, str(page_tuple))
    unique_pages = set(page_key(p) for p in pages)

    with tab1:
        st.markdown("<div class='tab-section-title'><span class='icon'>ğŸ“„</span> Flowë³„ ì„œë¹„ìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ ìš”ì•½</div>", unsafe_allow_html=True)
        flow_summaries = summarize_flow_service_natural(data)
        flows_data = data['context']['flows']
        for i, flow in enumerate(flows_data):
            flow_name = flow['name']
            pages_in_flow = flow['pages']
            # pageê°„ ì´ë™ í•´ì„
            page_links = []
            for page in pages_in_flow:
                for handler in page.get('handlers', []):
                    target = handler.get('transitionTarget', {})
                    if target.get('type') == 'CUSTOM' and target.get('page'):
                        page_links.append((page['name'], target['page']))
            # Graphviz ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            graph_lines = [f'digraph "{flow_name}" {{']
            for page in pages_in_flow:
                graph_lines.append(f'    "{page["name"]}";')
            for src, dst in page_links:
                graph_lines.append(f'    "{src}" -> "{dst}";')
            graph_lines.append('}')
            graph_str = '\n'.join(graph_lines)
            st.markdown(f"#### Flow: {flow_name}")
            st.graphviz_chart(graph_str)
            st.markdown(flow_summaries[i])
    with tab2:
        st.markdown("<div class='tab-section-title'><span class='icon'>ğŸ› ï¸</span> í•¸ë“¤ëŸ¬/ë³€ìˆ˜ ìƒì„¸ ìš”ì•½</div>", unsafe_allow_html=True)
        handler_df, variable_df, variable_usage = get_handler_variable_details(data)
        st.markdown("**[í•¸ë“¤ëŸ¬ ìš”ì•½]**")
        if not handler_df.empty:
            st.dataframe(handler_df, use_container_width=True)
        else:
            st.info("í•¸ë“¤ëŸ¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("**[ë³€ìˆ˜ ì‚¬ìš© ìš”ì•½]**")
        if not variable_df.empty:
            st.dataframe(variable_df, use_container_width=True)
            st.markdown("**[ë³€ìˆ˜ë³„ ìƒì„¸ ì„¤ëª…]**")
            for var, usages in variable_usage.items():
                st.markdown(f"**ë³€ìˆ˜ëª…: {var}** (ì´ {len(usages)}íšŒ ì‚¬ìš©)")
                usage_table = pd.DataFrame(usages)
                st.dataframe(usage_table, use_container_width=True)
                example_pages = usage_table['Page'].unique()
                example_handlers = usage_table['Handler Type'].unique()
                st.caption(f"- ì‚¬ìš© í˜ì´ì§€: {', '.join(example_pages)}")
                st.caption(f"- ì‚¬ìš© í•¸ë“¤ëŸ¬: {', '.join(example_handlers)}")
                example_conds = usage_table['Condition'].unique()
                if any(example_conds):
                    st.caption(f"- ì‚¬ìš© ì¡°ê±´ë¬¸ ì˜ˆì‹œ: {', '.join([c for c in example_conds if c])}")
                example_values = usage_table['Value'].unique()
                if any(example_values):
                    st.caption(f"- ê°’ ì˜ˆì‹œ: {', '.join([str(v) for v in example_values if v])}")
                st.markdown("---")
        else:
            st.info("ë³€ìˆ˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    with tab3:
        st.markdown("<div class='tab-section-title'><span class='icon'>ğŸ”</span> ì¸í…íŠ¸/ì—”í‹°í‹° ìš”ì•½ ë° ì˜¤ë¥˜ ê²€ìˆ˜</div>", unsafe_allow_html=True)
        intent_df, entity_df, intent_err_df, entity_err_df = get_intent_entity_summary(data)
        st.markdown(f"**[Intent ìš”ì•½ (ì´ {len(intent_df)}ê°œ)]**")
        if not intent_df.empty:
            st.dataframe(intent_df, use_container_width=True)
        else:
            st.info("ë“±ë¡ëœ Intentê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown(f"**[Entity ìš”ì•½ (ì´ {len(entity_df)}ê°œ)]**")
        if not entity_df.empty:
            st.dataframe(entity_df, use_container_width=True)
        else:
            st.info("ë“±ë¡ëœ Entityê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("**[Intent ì˜¤ë¥˜ ê²€ìˆ˜]**")
        if not intent_err_df.empty:
            st.dataframe(intent_err_df, use_container_width=True)
        else:
            st.info("Intent ì˜¤ë¥˜ ì—†ìŒ")
        st.markdown("**[Entity ì˜¤ë¥˜ ê²€ìˆ˜]**")
        if not entity_err_df.empty:
            st.dataframe(entity_err_df, use_container_width=True)
        else:
            st.info("Entity ì˜¤ë¥˜ ì—†ìŒ")

    # ì˜¤ë¥˜ ìœ í˜•ë³„ ê°œìˆ˜ ë° ë¹„ìœ¨
    error_types = [err['type'] for err in errors]
    error_type_counts = pd.Series(error_types).value_counts().reset_index()
    error_type_counts.columns = ['ì˜¤ë¥˜ ìœ í˜•', 'ê±´ìˆ˜']
    total_errors = len(errors)
    error_type_counts['ë¹„ìœ¨(%)'] = (error_type_counts['ê±´ìˆ˜'] / total_errors * 100).round(1)

    # Top N ì˜¤ë¥˜ ë©”ì‹œì§€
    top_n = 5
    top_errors = pd.DataFrame(errors)[:top_n] if errors else pd.DataFrame(columns=['type','message','location'])

    # ìµœê·¼ ì˜¤ë¥˜ ìœ„ì¹˜
    recent_locations = top_errors[['location','type','message']] if not top_errors.empty else pd.DataFrame(columns=['location','type','message'])

    # ì¹´ë“œí˜• ìš”ì•½
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Flow ìˆ˜", len(flows))
    col2.metric("Page ìˆ˜", len(unique_pages))  # ì „ì²´ Flow-Page ì¡°í•© ê¸°ì¤€
    col3.metric("í•¸ë“¤ëŸ¬ ìˆ˜", len(handlers))
    col4.metric("ë³€ìˆ˜ ìˆ˜", len(variables))

    st.subheader(":bar_chart: ì˜¤ë¥˜ ìœ í˜•ë³„ ë¶„í¬ (plotly)")
    fig = plot_error_types(errors)
    st.plotly_chart(fig, use_container_width=True)

    st.subheader(":clipboard: ì˜¤ë¥˜ ìœ í˜•ë³„ ìš”ì•½í‘œ")
    st.dataframe(error_type_counts, use_container_width=True)

    st.subheader(":trophy: Top 5 ì˜¤ë¥˜")
    if not top_errors.empty:
        st.table(top_errors[['type','message','location']])
    else:
        st.info("ì˜¤ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.subheader(":round_pushpin: ìµœê·¼ ì˜¤ë¥˜ ë°œìƒ ìœ„ì¹˜")
    if not recent_locations.empty:
        for idx, row in recent_locations.iterrows():
            st.write(f"- [{row['type']}] {row['location']} : {row['message']}")
    else:
        st.info("ìµœê·¼ ì˜¤ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.subheader("ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ")
    # ì—…ë¡œë“œí•œ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
    uploaded_filename = uploaded_file.name if uploaded_file else "uploaded"
    base_filename = os.path.splitext(uploaded_filename)[0]

    # ì—‘ì…€ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    excel_filename = f"{base_filename}_bot_report.xlsx"
    if st.button("ì—‘ì…€ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ"):
        excel_buffer = export_excel(errors, suggestions, filename=excel_filename)
        st.download_button("ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", excel_buffer, file_name=excel_filename)

    # PDF ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    pdf_filename = f"{base_filename}_bot_report.pdf"
    if st.button("PDF ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ"):
        pdf_buffer = export_pdf(errors, suggestions, filename=pdf_filename)
        st.download_button("PDF ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", pdf_buffer, file_name=pdf_filename)

if menu == "QA ê²€ìˆ˜ ê²°ê³¼" and data is not None:
    flows, pages, handlers, variables = analyze_bot_json(data)
    errors = validate_bot_json(data)

    # ë””ìì¸ ì—…ê·¸ë ˆì´ë“œ CSS (ì˜¤ë¥˜ ìƒì„¸ ì¹´ë“œ/ë°°ì§€/ë°•ìŠ¤)
    st.markdown("""
    <style>
    .flow-section {
        background: #f7f6ff;
        border-radius: 1.5rem;
        box-shadow: 0 2px 12px rgba(108,71,255,0.07);
        margin-bottom: 1.1rem;
        padding: 0.7rem 1.2rem 0.7rem 1.2rem;
        border: 1px solid #e0e0ff;
    }
    .flow-title {
        font-size: 1.25rem;
        font-weight: 900;
        color: #7c3aed;
        margin-bottom: 0.7rem;
        display: flex;
        align-items: center;
        gap: 0.7rem;
    }
    .page-error-table-header {
        display: flex;
        align-items: center;
        font-size: 1.01rem;
        font-weight: 700;
        color: #7c3aed;
        margin-bottom: 0.3rem;
        margin-left: 0.2rem;
    }
    .page-error-table-header .page-header-col {
        flex: 1 1 0;
        min-width: 120px;
    }
    .page-error-table-header .type-header-col {
        flex: 1 1 0;
        text-align: center;
    }
    .page-error-table-header .suggest-header-col {
        flex: 2 1 0;
        text-align: center;
        padding-left: 0.5rem;
        padding-right: 0.5rem;
    }
    .page-error-row {
        display: flex;
        align-items: stretch;
        background: #fff;
        border-radius: 1.1rem;
        box-shadow: 0 1px 4px rgba(108,71,255,0.04);
        margin-bottom: 0.4rem;
        padding: 0.7rem 1.1rem 0.7rem 1.1rem;
        border: 1px solid #ececff;
        width: 100%;
        min-height: 2.2rem;
    }
    .page-name {
        flex: 1 1 0;
        font-weight: 700;
        color: #2d2d3a;
        min-width: 120px;
        margin-right: 0.7rem;
        display: flex;
        align-items: center;
    }
    .error-type-badge {
        flex: 1 1 0;
        text-align: center;
        font-weight: 700;
        padding: 0.2rem 0.8rem;
        border-radius: 1rem;
        font-size: 1.02rem;
        color: #fff;
        margin: 0 auto;
        display: inline-block;
        min-width: 120px;
        max-width: 180px;
    }
    .HandlerMissing { background: #ff5c5c; }
    .ConditionError { background: #ffb300; color: #222; }
    .CustomCheck { background: #6c47ff; }
    .PageLinkError { background: #00b894; }
    .error-suggestion {
        flex: 2 1 0;
        color: #2d5fff;
        font-size: 0.98rem;
        font-weight: 600;
        margin-left: 0.2rem;
        display: flex;
        align-items: center;
        word-break: break-all;
        justify-content: center;
        text-align: center;
    }
    </style>
    """, unsafe_allow_html=True)

    st.markdown("<div class='tab-section-title'><span class='icon'>ğŸ“</span> ì˜¤ë¥˜ ìƒì„¸ ë° ìˆ˜ì • ì œì•ˆ</div>", unsafe_allow_html=True)
    use_openai = st.checkbox("OpenAI ê¸°ë°˜ ìë™ ìˆ˜ì • ì œì•ˆ ë³´ê¸°", value=False)
    suggestions = suggest_fixes(errors, data, use_openai=use_openai)

    # ì˜¤ë¥˜ë¥¼ Flowë³„ë¡œ ê·¸ë£¹í•‘
    flow_errors = defaultdict(list)
    for i, err in enumerate(errors):
        flow = err['location'].split('>')[0].strip() if '>' in err['location'] else err['location']
        flow_errors[flow].append((i, err))

    for flow, err_list in flow_errors.items():
        st.markdown(f"<div class='flow-section'>", unsafe_allow_html=True)
        st.markdown(f"<div class='flow-title'>ğŸ“ Flow: {flow}</div>", unsafe_allow_html=True)
        # íƒ€ì´í‹€ í–‰ ì¶”ê°€
        st.markdown("""
            <div class='page-error-table-header'>
                <div class='page-header-col'>Pageëª…</div>
                <div class='type-header-col'>ì˜¤ë¥˜ìœ í˜•</div>
                <div class='suggest-header-col'>ìˆ˜ì •ì œì•ˆ</div>
            </div>
        """, unsafe_allow_html=True)
        for i, err in err_list:
            emoji = {
                "HandlerMissing": "ğŸ”´",
                "ConditionError": "ğŸŸ¡",
                "PageLinkError": "ğŸŸ¢",
                "CustomCheck": "ğŸŸ£"
            }.get(err['type'], "âš ï¸")
            badge_class = f"error-type-badge {err['type']}"
            page_name = err['location'].split('>')[1].strip() if '>' in err['location'] else err['location']
            st.markdown(f"""
                <div class='page-error-row'>
                    <span class='page-name'>{page_name}</span>
                    <span class='{badge_class}'>{emoji} {err['type']}</span>
                    <span class='error-suggestion'>{err['suggestion'] or ''}</span>
                </div>
            """, unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

    # ìë™ ìˆ˜ì • ì œì•ˆ ìš”ì•½ - Pageë³„ í‘œ
    summary_rows = []
    for err, sug in zip(errors, suggestions):
        page = err['location']
        summary_rows.append({
            "Page": page,
            "ì˜¤ë¥˜ ìœ í˜•": err['type'],
            "ì˜¤ë¥˜ ë©”ì‹œì§€": err['message'],
            "ìˆ˜ì • ì œì•ˆ": err['suggestion'] or sug
        })
    import pandas as pd
    summary_df = pd.DataFrame(summary_rows)
    st.markdown("<div class='tab-section-title'><span class='icon'>ğŸ“‹</span> ìë™ ìˆ˜ì • ì œì•ˆ ìš”ì•½ (Pageë³„)</div>", unsafe_allow_html=True)
    st.dataframe(summary_df, use_container_width=True)
    # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
    import io
    def to_excel_bytes_summary(df):
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False)
        output.seek(0)
        return output
    excel_bytes_summary = to_excel_bytes_summary(summary_df)
    # ì—…ë¡œë“œ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
    uploaded_filename = uploaded_file.name if uploaded_file else "uploaded"
    base_filename = os.path.splitext(uploaded_filename)[0]
    summary_excel_filename = f"{base_filename}_summary.xlsx"
    st.download_button(
        label="ìë™ ìˆ˜ì • ì œì•ˆ ìš”ì•½ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=excel_bytes_summary,
        file_name=summary_excel_filename,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

if menu == "JSON êµ¬ì¡° íŒŒì•…" and data is not None:
    flow_df, intent_df, entity_df = parse_bot_structure_from_data(data)
    st.subheader("Flow/Page/Handler êµ¬ì¡°")
    for flow_name in flow_df["Flow"].unique():
        st.markdown(f"### ğŸ—‚ï¸ Flow: {flow_name}")
        flow_part = flow_df[flow_df["Flow"] == flow_name].copy()
        show_cols = ["Page", "Handler_ID", "Handler_Type", "Handler_Condition", "Handler_Action", "Handler_TransitionTarget", "Page_Action", "Page_Parameters", "Handler_ParameterPresets"]
        st.dataframe(flow_part[show_cols].reset_index(drop=True), use_container_width=True)
    st.subheader("Intent ì •ë³´")
    st.dataframe(intent_df, use_container_width=True)
    st.subheader("Entity ì •ë³´")
    st.dataframe(entity_df, use_container_width=True)
    import io
    if st.button("ì—‘ì…€ íŒŒì¼ë¡œ ë³€í™˜"):
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            flow_df.to_excel(writer, sheet_name="Flow_Page_Handler", index=False)
            intent_df.to_excel(writer, sheet_name="Intent", index=False)
            entity_df.to_excel(writer, sheet_name="Entity", index=False)
        output.seek(0)
        st.success("ì—‘ì…€ íŒŒì¼ë¡œ ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.download_button(
            label="ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=output,
            file_name="bot_structure.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

if menu == "Response Text ê²€ì¶œ" and data is not None:
    st.write("ê° Flow/Pageë³„ Response í…ìŠ¤íŠ¸(<p>...</p>)ë¥¼ ì¶”ì¶œí•˜ì—¬ í‘œë¡œ ë³´ì—¬ì£¼ê³ , ê° Responseë³„ ì˜¤íƒ€ë¥¼ OpenAIë¡œ ê²€ì‚¬í•©ë‹ˆë‹¤.")
    rows = extract_response_texts_by_flow(data)
    rows = [row for row in rows if row.get('Response Text') not in [None, '', 'null']]
    if not rows:
        st.info("Response í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        import pandas as pd
        df = pd.DataFrame(rows)
        typo_results = {}
        if st.button("Response Text ì˜¤íƒ€ ê²€ìˆ˜ ì‹¤í–‰(by OpenAI, JSON, ë³‘ë ¬)"):
            flow_groups = list(df.groupby('Flow'))
            total = len(flow_groups)
            progress = st.progress(0, text="ì˜¤íƒ€ ë¶„ì„ ì§„í–‰ ì¤‘...")
            start_time = time.time()
            def typo_check_for_flow(flow, group):
                texts = group['Response Text'].tolist()
                return flow, check_typo_openai_responses_json(texts)
            with ThreadPoolExecutor(max_workers=5) as executor:
                futures = [executor.submit(typo_check_for_flow, flow, group) for flow, group in flow_groups]
                for idx, future in enumerate(as_completed(futures)):
                    flow, results = future.result()
                    for r in results:
                        typo_results[(flow, r.text)] = (r.typo, r.reason)
                    progress.progress((idx + 1) / total, text=f"ì˜¤íƒ€ ë¶„ì„: {idx + 1}/{total} Flow ì™„ë£Œ")
            st.success(f"Response Text ì˜¤íƒ€ ê²€ì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! (ì´ ì†Œìš”: {time.time() - start_time:.1f}s)")
        # í‘œì— ì˜¤íƒ€ ê²°ê³¼ ì»¬ëŸ¼ ì¶”ê°€
        def get_typo_result(row):
            key = (row['Flow'], row['Response Text'])
            if key in typo_results:
                typo, reason = typo_results[key]
                return f"ì˜¤íƒ€ ìˆìŒ: {reason}" if typo else "ì˜¤íƒ€ ì—†ìŒ"
            return '(ê²€ì‚¬ ì „)'
        df['ì˜¤íƒ€ ê²€ì¶œ ê²°ê³¼(Responseë³„)'] = df.apply(get_typo_result, axis=1)
        # Handler_ID ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ëª¨ë‘ ë¬¸ìì—´ë¡œ ë³€í™˜ (Arrow ì˜¤ë¥˜ ë°©ì§€)
        if 'Handler_ID' in df.columns:
            df['Handler_ID'] = df['Handler_ID'].astype(str)
        st.dataframe(df, use_container_width=True)
        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        def to_excel_bytes(df):
            output = BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df.to_excel(writer, index=False)
            output.seek(0)
            return output
        excel_bytes = to_excel_bytes(df)
        st.download_button(
            label="ì—‘ì…€ë¡œ ë‹¤ìš´í•˜ê¸°",
            data=excel_bytes,
            file_name="response_typo_check.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
